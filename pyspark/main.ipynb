{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.window import Window\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"LayerZeroTransactionAnalysis\") \\\n",
    "    .config(\"spark.executor.memory\", \"6g\") \\\n",
    "    .config(\"spark.driver.memory\", \"6g\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- SOURCE_CHAIN: string (nullable = true)\n",
      " |-- SOURCE_TRANSACTION_HASH: string (nullable = true)\n",
      " |-- DESTINATION_CHAIN: string (nullable = true)\n",
      " |-- DESTINATION_TRANSACTION_HASH: string (nullable = true)\n",
      " |-- SENDER_WALLET: string (nullable = true)\n",
      " |-- SOURCE_TIMESTAMP_UTC: timestamp (nullable = true)\n",
      " |-- PROJECT: string (nullable = true)\n",
      " |-- NATIVE_DROP_USD: double (nullable = true)\n",
      " |-- STARGATE_SWAP_USD: double (nullable = true)\n",
      "\n",
      "+------------+-----------------------+-----------------+----------------------------+--------------------+--------------------+-------+---------------+-----------------+\n",
      "|SOURCE_CHAIN|SOURCE_TRANSACTION_HASH|DESTINATION_CHAIN|DESTINATION_TRANSACTION_HASH|       SENDER_WALLET|SOURCE_TIMESTAMP_UTC|PROJECT|NATIVE_DROP_USD|STARGATE_SWAP_USD|\n",
      "+------------+-----------------------+-----------------+----------------------------+--------------------+--------------------+-------+---------------+-----------------+\n",
      "|    Optimism|   0x45017be8ad994b9...|  Orderly Mainnet|        0x175cf6f9916eaa8...|0x56012d5f113ac74...| 2023-11-10 03:00:03| Merkly|           NULL|             NULL|\n",
      "|    Optimism|   0xc613716f07ae303...|  Orderly Mainnet|        0x3fc3f923134c2e4...|0x3ac2bbdcdaba8da...| 2023-11-12 19:43:17| Merkly|           NULL|             NULL|\n",
      "|    Optimism|   0x6c08814fd36b2c9...|  Orderly Mainnet|        0x397ce0de654c1c4...|0xfd0c7eb57d05ecf...| 2023-11-15 09:28:07| Merkly|           NULL|             NULL|\n",
      "|     Polygon|   0xd5261236e302344...|    Arbitrum Nova|        0xfab6a9981cd55c6...|0x428b49419217481...| 2024-01-03 09:38:21|   NULL|           NULL|             NULL|\n",
      "|     Polygon|   0xc2a8a218e9e1e8d...|        Moonriver|        0x195a60acc7715a8...|0x1457fcedfb8c83f...| 2024-01-21 12:50:34| Merkly|     1.04604311|             NULL|\n",
      "+------------+-----------------------+-----------------+----------------------------+--------------------+--------------------+-------+---------------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv('./data/snapshot1_transactions.csv', header=True, inferSchema=True)\n",
    "\n",
    "df.printSchema()\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 19\u001b[0m\n\u001b[0;32m     17\u001b[0m features \u001b[38;5;241m=\u001b[39m pandas_df[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mavg_daily_txn\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtotal_native_drop_usd\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mavg_native_drop_usd\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtotal_stargate_swap_usd\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mavg_stargate_swap_usd\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m     18\u001b[0m dbscan \u001b[38;5;241m=\u001b[39m DBSCAN(eps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m, min_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m---> 19\u001b[0m pandas_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcluster\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdbscan\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(pandas_df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSENDER_WALLET\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcluster\u001b[39m\u001b[38;5;124m'\u001b[39m]])\n",
      "File \u001b[1;32md:\\aCode\\python-learn\\.venv\\lib\\site-packages\\sklearn\\cluster\\_dbscan.py:472\u001b[0m, in \u001b[0;36mDBSCAN.fit_predict\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    447\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit_predict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    448\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute clusters from a data or distance matrix and predict labels.\u001b[39;00m\n\u001b[0;32m    449\u001b[0m \n\u001b[0;32m    450\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    470\u001b[0m \u001b[38;5;124;03m        Cluster labels. Noisy samples are given the label -1.\u001b[39;00m\n\u001b[0;32m    471\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 472\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels_\n",
      "File \u001b[1;32md:\\aCode\\python-learn\\.venv\\lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\aCode\\python-learn\\.venv\\lib\\site-packages\\sklearn\\cluster\\_dbscan.py:420\u001b[0m, in \u001b[0;36mDBSCAN.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    418\u001b[0m neighbors_model\u001b[38;5;241m.\u001b[39mfit(X)\n\u001b[0;32m    419\u001b[0m \u001b[38;5;66;03m# This has worst case O(n^2) memory complexity\u001b[39;00m\n\u001b[1;32m--> 420\u001b[0m neighborhoods \u001b[38;5;241m=\u001b[39m \u001b[43mneighbors_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mradius_neighbors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_distance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    422\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    423\u001b[0m     n_neighbors \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;28mlen\u001b[39m(neighbors) \u001b[38;5;28;01mfor\u001b[39;00m neighbors \u001b[38;5;129;01min\u001b[39;00m neighborhoods])\n",
      "File \u001b[1;32md:\\aCode\\python-learn\\.venv\\lib\\site-packages\\sklearn\\neighbors\\_base.py:1263\u001b[0m, in \u001b[0;36mRadiusNeighborsMixin.radius_neighbors\u001b[1;34m(self, X, radius, return_distance, sort_results)\u001b[0m\n\u001b[0;32m   1261\u001b[0m n_jobs \u001b[38;5;241m=\u001b[39m effective_n_jobs(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)\n\u001b[0;32m   1262\u001b[0m delayed_query \u001b[38;5;241m=\u001b[39m delayed(_tree_query_radius_parallel_helper)\n\u001b[1;32m-> 1263\u001b[0m chunked_results \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1264\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed_query\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1265\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tree\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43ms\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mradius\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_distance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msort_results\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort_results\u001b[49m\n\u001b[0;32m   1266\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1267\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgen_even_slices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1268\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1269\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_distance:\n\u001b[0;32m   1270\u001b[0m     neigh_ind, neigh_dist \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mchunked_results))\n",
      "File \u001b[1;32md:\\aCode\\python-learn\\.venv\\lib\\site-packages\\sklearn\\utils\\parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     66\u001b[0m )\n\u001b[1;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\aCode\\python-learn\\.venv\\lib\\site-packages\\joblib\\parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32md:\\aCode\\python-learn\\.venv\\lib\\site-packages\\joblib\\parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32md:\\aCode\\python-learn\\.venv\\lib\\site-packages\\sklearn\\utils\\parallel.py:129\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    127\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\aCode\\python-learn\\.venv\\lib\\site-packages\\sklearn\\neighbors\\_base.py:1041\u001b[0m, in \u001b[0;36m_tree_query_radius_parallel_helper\u001b[1;34m(tree, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1035\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_tree_query_radius_parallel_helper\u001b[39m(tree, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   1036\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Helper for the Parallel calls in RadiusNeighborsMixin.radius_neighbors.\u001b[39;00m\n\u001b[0;32m   1037\u001b[0m \n\u001b[0;32m   1038\u001b[0m \u001b[38;5;124;03m    The Cython method tree.query_radius is not directly picklable by\u001b[39;00m\n\u001b[0;32m   1039\u001b[0m \u001b[38;5;124;03m    cloudpickle under PyPy.\u001b[39;00m\n\u001b[0;32m   1040\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1041\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tree\u001b[38;5;241m.\u001b[39mquery_radius(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32msklearn\\\\neighbors\\\\_binary_tree.pxi:1438\u001b[0m, in \u001b[0;36msklearn.neighbors._kd_tree.BinaryTree64.query_radius\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32msklearn\\\\neighbors\\\\_binary_tree.pxi:1391\u001b[0m, in \u001b[0;36msklearn.neighbors._kd_tree.BinaryTree64.query_radius\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from sklearn.cluster import DBSCAN\n",
    "import numpy as np\n",
    "\n",
    "transaction_freq = df.groupBy(\"SENDER_WALLET\", F.window(\"SOURCE_TIMESTAMP_UTC\", \"1 day\")).count()\n",
    "avg_daily_txn = transaction_freq.groupBy(\"SENDER_WALLET\").agg(F.avg(\"count\").alias(\"avg_daily_txn\"))\n",
    "amount_stats = df.groupBy(\"SENDER_WALLET\").agg(\n",
    "    F.sum(\"NATIVE_DROP_USD\").alias(\"total_native_drop_usd\"),\n",
    "    F.avg(\"NATIVE_DROP_USD\").alias(\"avg_native_drop_usd\"),\n",
    "    F.sum(\"STARGATE_SWAP_USD\").alias(\"total_stargate_swap_usd\"),\n",
    "    F.avg(\"STARGATE_SWAP_USD\").alias(\"avg_stargate_swap_usd\")\n",
    ")\n",
    "feature_df = avg_daily_txn.join(amount_stats, \"SENDER_WALLET\")\n",
    "pandas_df = feature_df.toPandas()\n",
    "\n",
    "\n",
    "features = pandas_df[[\"avg_daily_txn\", \"total_native_drop_usd\", \"avg_native_drop_usd\", \"total_stargate_swap_usd\", \"avg_stargate_swap_usd\"]].fillna(0).values\n",
    "dbscan = DBSCAN(eps=0.5, min_samples=5)\n",
    "pandas_df['cluster'] = dbscan.fit_predict(features)\n",
    "print(pandas_df[['SENDER_WALLET', 'cluster']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------+------------------------------------------+-----+\n",
      "|window                                    |SENDER_WALLET                             |count|\n",
      "+------------------------------------------+------------------------------------------+-----+\n",
      "|{2024-02-06 22:44:00, 2024-02-06 22:45:00}|0x2a9e0c195bd235e7eed5c8b6a52857e59bc2733d|600  |\n",
      "|{2024-02-07 00:29:00, 2024-02-07 00:30:00}|0x4bc295dfdf62501cebbc9be3157d3fccdd3f12ce|500  |\n",
      "|{2024-02-07 23:25:00, 2024-02-07 23:26:00}|0xb1b09b57b8be1d0ce65555d68f7c677dc80ad29e|500  |\n",
      "|{2024-04-24 18:13:00, 2024-04-24 18:14:00}|0x81698d4be3c2cde0fbd2cc457ba1aa0d5df11ddd|456  |\n",
      "|{2024-04-24 18:14:00, 2024-04-24 18:15:00}|0x81698d4be3c2cde0fbd2cc457ba1aa0d5df11ddd|420  |\n",
      "+------------------------------------------+------------------------------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 按1分钟的时间窗口统计每个发送者的交易数\n",
    "windowed_sender_distribution = df.groupBy(\n",
    "    F.window(\"SOURCE_TIMESTAMP_UTC\", \"1 minutes\"),  # 1分钟的时间窗口\n",
    "    \"SENDER_WALLET\"\n",
    ").count()\n",
    "\n",
    "short_time_suspicious_senders = windowed_sender_distribution.filter(F.col(\"count\") > 100).orderBy(F.col(\"count\").desc())\n",
    "short_time_suspicious_senders.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----+------------------+\n",
      "|       SENDER_WALLET|              window|count|total_transactions|\n",
      "+--------------------+--------------------+-----+------------------+\n",
      "|0x0f9d76acdbc4417...|{2024-02-07 05:49...|  111|               123|\n",
      "|0x31e9063813533cb...|{2024-03-01 10:09...|  110|               117|\n",
      "|0xfa3e289c03bf7af...|{2024-04-30 19:10...|  101|               120|\n",
      "+--------------------+--------------------+-----+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sender_activity = df.groupBy(\"SENDER_WALLET\").agg(F.count(\"*\").alias(\"total_transactions\"))\n",
    "suspicious_senders = short_time_suspicious_senders.join(sender_activity, on=\"SENDER_WALLET\") \\\n",
    "    .filter((F.col(\"total_transactions\") < 150) & (F.col(\"count\") > 100))\n",
    "\n",
    "suspicious_senders.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------+-----------------+\n",
      "|PROJECT|SENDER_WALLET|interaction_times|\n",
      "+-------+-------------+-----------------+\n",
      "+-------+-------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Filter dapp\n",
    "sybil_projects = [\"merkly\", \"l2pass\"]\n",
    "filtered_df = df.filter(F.col(\"PROJECT\").isin(sybil_projects))\n",
    "\n",
    "window_spec = Window.partitionBy(\"SENDER_WALLET\", \"PROJECT\").orderBy(\"SOURCE_TIMESTAMP_UTC\")\n",
    "filtered_df = filtered_df.withColumn(\"prev_timestamp\", F.lag(\"SOURCE_TIMESTAMP_UTC\").over(window_spec))\n",
    "filtered_df = filtered_df.withColumn(\"time_diff\", F.unix_timestamp(\"SOURCE_TIMESTAMP_UTC\") - F.unix_timestamp(\"prev_timestamp\"))\n",
    "\n",
    "path_df = filtered_df.groupBy(\"PROJECT\", \"SENDER_WALLET\").agg(F.collect_list(\"time_diff\").alias(\"interaction_times\"))\n",
    "path_df.show(5, truncate=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
